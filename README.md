# Building a Large Language Model from Scratch

This project is a personal endeavor to develop a GPT-like Large Language Model (LLM) from the ground up, utilizing the book *Build a Large Language Model (From Scratch)* by Sebastian Raschka. The goal is to follow the book step by step while integrating personalized data to create a custom LLM.

## Project Overview

The project is structured to mirror the chapters of Raschka's book, covering topics such as:

1. **Understanding Large Language Models**: Exploring the fundamentals and architectures of LLMs.
2. **Working with Text Data**: Techniques for processing and preparing text data for model training.
3. **Coding Attention Mechanisms**: Implementing attention mechanisms crucial for LLM functionality.
4. **Implementing a GPT Model from Scratch**: Building the core GPT architecture.
5. **Pretraining on Unlabeled Data**: Training the model on large datasets without labels.
6. **Finetuning for Specific Tasks**: Adapting the pretrained model for specific applications like text classification.
7. **Instruction Following and Human Feedback**: Enhancing the model's ability to follow instructions and incorporate feedback.

## Development Log

Progress and insights are documented in a development log, accessible [here](https://medium.com/@h.lukejang). This log includes:

- **Daily Updates**: Summaries of daily progress, challenges faced, and solutions implemented.
- **Code Snippets**: Key code implementations and explanations.
- **Learnings and Reflections**: Insights gained throughout the development process.

## Getting Started

To replicate or build upon this project:

1. **Clone the Repository**:

   ```bash
   git clone --depth 1 https://github.com/wkdghdus/LLM.git
   ```

2. **Install Dependencies**:

   Navigate to the project directory and install the required packages:

   ```bash
   pip install -r requirements.txt
   ```

3. **Set Up the Environment**:

   Follow the setup instructions provided in the project repository.

## Acknowledgments

Special thanks to Sebastian Raschka for providing a comprehensive guide and codebase through his book, which serves as the foundation for this project.

---

*Note: This project is a personal learning endeavor and is not officially affiliated with Sebastian Raschka or his original works.*
